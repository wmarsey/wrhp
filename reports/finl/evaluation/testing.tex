\section{Unit testing the CLI}
We use the python `unittest' package to automate most of our
testing. The tests can be found in the package root folder in the
script `tester.py' (see appendix~\ref{sec:dirtree}).

Most of the test cases test the argParser.py logic --- the module that
checks for errors in the CLI arguments --- as most of the classes only
fail in their tasks given incorrect parameters. We also pay special
attention to the return values of each class --- in particular the
return values on failure. In our package, all exits are intended to be
handled by, and filtered up to, the wrhp.py main() function, so these
functions must fail gracefully.

\section{Evaluation of storage system}
The database was written initially to take the uniqueness of pageid
and revids for granted, but, as the project grew and we began fetching
from different language Wikipedias, the database had to change in
order to allow for duplicates of both page and revision ID, by adding
columns to all tables, and modifying their primary keys.

The database has grew organically with the project in other ways too,
and so is un-normalised. It has proven to quite robust and reliable,
but as the database grew it became quite slow. We believe it's
structure could be improved a little in order to reduce its size.

\begin{wrapfigure}{R}{0.45\linewidth}
  \begin{lstlisting}[
      basicstyle=\footnotesize,
      basicstyle=\linespread{0.8}\ttfamily,
    mathescape = true]
    P = Pageid
    T = Page title
    R = Revid
    D = Domain
    Cn = Content
    Un = Username
    Ui = Ui
    T = Revision timestampx
    S = Revision size
    Cm = Revision comment
    Mw = Math weight
    Cw = Citation weight
    Fw = Files / Images weight
    Lw = Link weight
    Sw = Structure weight
    Nw = Normal text weight
    G = Trajectory gradient
    Td = Trajectory distance
    F = Fetched flag

    RD $\rightarrow$ PMwCwFwLwSwNwCnCmGSTUnUiTd
    PD $\rightarrow$ TF
    UnD $\rightarrow$ Ui
  \end{lstlisting}
  \caption{Database fields and key dependencies}
  \label{fig:dat-key}
\end{wrapfigure}

Figure~\ref{fig:dat-key} lists the fields and key dependencies of the
database. Many of the entities of the database rely on the $(revid,
domain)$ key-pair, the only exception being the $Username, Domain
\rightarrow UserID$ and $Pageid, Domain \rightarrow Title, Fetched
flag$ relations.

Comparing this to the database schema as they stand in
figure~\ref{database-schema} we see that some improvements could be
made immediately -- the $Username, Domain \rightarrow UserID$ relation
could receive its own schema immediately, saving a lot of repeated
information in the `wikirevisions' table. This would also be useful as
the relation could easily be expanded upon on further study into
individual user habits, as I will suggest later.

Similarly, the `title' attribute of the `wikirevisions' table could be
moved to the `wikifetched' table, since it is unique to a
$(pageid,domain)$ pair. This would necessitate the addition of a
boolean column `fetched' to the same table (the presence or lack of
presence of a given $(pageid,domain)$ pair in the `wikifetched' table
currently stands in place of that boolean value). However, given that
`wikifetched' is inevitably much smaller than `wikirevisions', the
space saved would be considerable regardless.

A further feature that can be done away with is the presence of two
revision IDs in the `wikitrajectory' table. This was useful in an
earlier implementations, where the code would manually check for both
$(oldrevid,newrevid)$ and $(newrevid,oldrevid)$ pairs before
endeavouring to compute a new distance. This feature was scrubbed
early but the form of the table has survived. Similarly, content had
its own table to facilitate quicker access to revision content before
the on-line viewing feature was implemented in the CLI. We could move
content to the `wikirevisions' table, safely take on the convention of
the trajectory distance being unique to either the parent or child ID,
and reduce the `wikitrajectory' table by one column.

Some structural inelegance aside, the database is fairly robust. But
given the above analysis we should recommend adoption of the schemata
described in ~\ref{fig:database-new}. Some separation of
figure~\ref{fig:dat-key}'s larger relation is recommended, to reduce
the space required, whilst keeping the some table separations for
performance and maintenance's sake. The large content table is kept
separate from the rest of the data, so as to not slow down the
database, even though a normalised database would have this data in
the wikirevisions table. Maintenance-wise, if one of the distance
calculations goes awry, for instance, one would merely have to wipe
one table and recalculate.

\begin{figure}
  \centering
  \makebox[\linewidth][c]{
    \begin{subfigure}[b!]{0.4\linewidth}
      \centering
      \begin{tabular}{ccc}
        \toprule
        \underline{username} & \underline{domain} & userid\\
        \midrule
        $\vdots$ & $\vdots$ & $\vdots$\\
      \end{tabular}
      \caption{Table: wikicontent}
    \end{subfigure}
    \begin{subfigure}[b!]{0.4\linewidth}
      \centering
      \begin{tabular}{cccc}
        \toprule
        \underline{pageid} & \underline{domain} & title & fetched? \\
        \midrule
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$\\
      \end{tabular}
      \caption{Table: wikipages}
    \end{subfigure}
    \begin{subfigure}[b!]{0.4\linewidth}
      \centering
      \begin{tabular}{ccc}
        \toprule
        \underline{revid} & \underline{domain} & distance\\
        \midrule
        $\vdots$ & $\vdots$ & $\vdots$ \\
      \end{tabular}
      \caption{Table: wikitrajectory}
    \end{subfigure}
  }\\
  \vspace{10 mm}
  \begin{subfigure}[b!]{\linewidth}
    \centering
    \begin{tabular}{ccccccccc}
      \toprule
      \underline{revid} & \underline{domain} & pageid & username & time & size &
      comment & content \\ 
      \midrule
      $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$
      & $\vdots$ & $\vdots$ \\
    \end{tabular}
    \caption{Table: wikirevisions}
  \end{subfigure}\\
  \vspace{10 mm}
  \begin{subfigure}[b!]{\linewidth}
    \centering
    \begin{tabular}{ccccccccc}
      \toprule
      \underline{revid} & \underline{domain} & maths & citations & filesimages & links &
      structure & normal & gradient\\
      \midrule
      $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ &
      $\vdots$ & $\vdots$ & $\vdots$ \\
    \end{tabular}
    \caption{Table: wikiweights} 
  \end{subfigure}
  \caption{Recommended new schemata for storing wikipedia data}
  \label{fig:database-new}
\end{figure}

Since, as demonstrated, we may rely on $(pageid,$ $domain)$ and
$(revid,domain)$ pairs, we are able to embed these as native psql
primary key restraints. The database will throw error `23000,
integrity constraint violation' if this restraint is threatened by the
next transaction, which is passed up from the psycopg module as an
exception.\cite{psql-error}\cite{psyc-error} If such an error occurs,
we catch it, log it, and terminate the program cleanly.

In reality, though, these errors are infrequent. The code only
prepares and inserts a value if it cannot find it in the database, and
the insertion functions are implemented as to check before inserting
that it will not be duplicating any data.
